# Redis

**怎么样解决热Key的问题？**

1. 拆

   1. big list： list1、list2、...listN

   - big hash：可以讲数据分段存储，比如一个大的key，假设存了1百万的用户数据，可以拆分成200个key，每个key下面存放5000个用户数据

   - 如果bigkey不可避免，也要思考一下要不要每次把所有元素都取出来(例如有时候仅仅需要hmget，而不是hgetall)，删除也是一样，尽量使用优雅的方式来处理。

2. 【推荐】：选择适合的数据类型。

   例如：实体类型(要合理控制和使用数据结构，但也要注意节省内存和性能之间的平衡)

   反例：

   ```java
   set user:1:name tom set user:1:age 19 set user:1:favor football
   ```

   正例:           

   ```java
   hmset user:1 name tom age 19 favor football               
   ```

   

3. 【推荐】：控制key的生命周期，redis不是垃圾桶。

   建议使用expire设置过期时间(条件允许可以打散过期时间，防止集中过期)。开启异步删除key

   ```c++
   lazyfree-lazy-server-del //内部删除选项，比如rename oldkey newkey时，如果newkey存在需要删除newkey
   ```

**bigkey的查找**

1. **使用 Redis 自带的 --bigkeys 参数来查找。**

   从这个命令的运行结果，我们可以看出：这个命令会扫描(Scan) Redis 中的所有 key ，会对 Redis 的性能有一点影响。并且，这种方式只能找出每种数据结构 top 1 bigkey（占用内存最大的 string 数据类型，包含元素最多的复合数据类型）。

2. 通过分析 RDB 文件来找出 big key。这种方案的前提是你的 Redis 采用的是 RDB 持久化。

网上有现成的代码/工具可以直接拿来使用：

- **redis-rdb-tools**：Python 语言写的用来分析 Redis 的 RDB 快照文件用的工具
- **rdb_bigkeys**: Go 语言写的用来分析 Redis 的 RDB 快照文件用的工具，性能更好。

## hostkey

### **hotkey如何发现?**

#### **redis**自带参数

**hotkeys 参数**

`Redis` 在 `4.0.3` 版本中添加了 [hotkeys](https://github.com/redis/redis/pull/4392) 查找特性，可以直接利用 `redis-cli --hotkeys` 获取当前 `keyspace` 的热点 `key`，实现上是通过 `scan + object freq` 完成的。

- 优点：无需进行二次开发，能够直接利用现成的工具；
- 缺点：
  - 由于需要扫描整个 `keyspace`，实时性上比较差;
  - 扫描时间与 `key` 的数量正相关，如果 `key` 的数量比较多，耗时可能会非常长。

**monitor 命令**

`monitor` 命令可以实时抓取出 `Redis` 服务器接收到的命令，通过 `redis-cli monitor` 抓取数据，同时结合一些现成的分析工具，比如 [redis-faina](https://github.com/facebookarchive/redis-faina)，统计出热 Key。

- 优点：无需进行二次开发，能够直接利用现成的工具；
- 缺点：该命令在高并发的条件下，有内存增暴增的隐患，还会降低 `Redis` 的性能。

#### Redis 节点抓包分析

`Redis` 客户端使用 `TCP` 协议与服务端进行交互，通信协议采用的是 `RESP` 协议。自己写程序监听端口，按照 `RESP` 协议规则解析数据，进行分析。或者我们可以使用一些抓包工具，比如 `tcpdump` 工具，抓取一段时间内的流量进行解析。

- 优点：对 `SDK` 或者 `Proxy` 代理层没有入侵；
- 缺点：
  - 有一定的开发成本；
  - 热 `Key` 节点的网络流量和系统负载已经比较高了，抓包可能会导致情况进一步恶化。

#### 凭借业务经验，预估热 Key 出现

根据业务系统上线的一些活动和功能，我们是可以在某些场景下提前预估热 `Key` 的出现的，比如业务需要进行一场商品秒杀活动，秒杀商品信息和数量一般都会缓存到 `Redis` 中，这种场景极有可能出现热 `Key` 问题的。

- 优点：简单，凭经验发现热 `Key`，提早发现提早处理；
- 缺点：没有办法预测所有热 `Key` 出现，比如某些热点新闻事件，无法提前预测。

#### 客户端进行收集

一般我们在连接 `Redis` 服务器时都要使用专门的 SDK（比如：`Java` 的客户端工具 `Jedis`、`Redisson`），我们可以对客户端工具进行封装，在发送请求前进行收集采集，同时定时把收集到的数据上报到统一的服务进行聚合计算。

- 优点：方案简单
- 缺点：
  - 对客户端代码有一定入侵，或者需要对 `SDK` 工具进行二次开发；
  - 没法适应多语言架构，每一种语言的 `SDK` 都需要进行开发，后期开发维护成本较高。

#### 在代理层进行收集

如果所有的 `Redis` 请求都经过 `Proxy`（代理）的话，可以考虑改动 `Proxy` 代码进行收集，思路与客户端基本类似。



- 优点：对使用方完全透明，能够解决客户端 `SDK` 的语言异构和版本升级问题；
- 缺点：
  - 开发成本会比客户端高些；
  - 并不是所有的 `Redis` 集群架构中都有 `Proxy` 代理（使用这种方式必须要部署 `Proxy`）。

### 解决方案

#### 1. 使用本地缓存

在 client 端使用本地缓存，从而降低了redis集群对hot key的访问量，但是同时带来两个问题：1、如果对可能成为 hot key 的 key 都进行本地缓存，那么本地缓存是否会过大，从而影响应用程序本身所需的缓存开销。2、如何保证本地缓存和redis集群数据的有效期的一致性。 
针对这两个问题，先不展开讲，先讲第二个解决方案。

#### 2. 利用分片算法的特性，对key进行打散处理

我们知道 hot key 之所以是 hot key，是因为它只有一个key，落地到一个实例上。**所以我们可以给hot key加上前缀或者后缀，把一个hotkey 的数量变成 redis 实例个数N的倍数M，从而由访问一个 redis key 变成访问 N * M 个redis key**。通过一个大于等于 1 小于 M * N 的随机数，得到一个 tmp key，程序会优先访问tmp key，在得不到数据的情况下，再访问原来的 hot key，并将 hot key的内容写回 tmp key。值得注意的是，tmp key的过期时间是 hot key 的过期时间加上一个较小的随机正整数，保证在 hot key 过期时，所有 tmp key 不会同时过期而造成缓存雪崩。这是一种通过坡度过期的方式来避免雪崩的思路，同时也可以利用原子锁来写入数据就更加的完美，减小db的压力。

# Mysql

# 分布式ID

## 美团Leaf-snowflake

Leaf-snowflake方案完全沿用snowflake方案的bit位设计，即是“1+41+10+12”的方式组装ID号。对于workerID的分配，当服务集群数量较小的情况下，完全可以手动配置。Leaf服务规模较大，动手配置成本太高。所以使用Zookeeper持久顺序节点的特性自动对snowflake节点配置wokerID。

### 弱依赖ZooKeeper

除了每次会去ZK拿数据以外，也会在本机文件系统上缓存一个workerID文件。当ZooKeeper出现问题，恰好机器出现问题需要重启时，能保证服务能够正常启动。这样做到了对三方组件的弱依赖。一定程度上提高了SLA。

### 解决时钟问题

因为这种方案依赖时间，如果机器的时钟发生了回拨，那么就会有可能生成重复的ID号，需要解决时钟回退的问题。**主要解决方案是在leaf_forever下面保存系统时间，leaf_temporary所有运行中的Leaf-snowflake节点。**

1. 若写过，则用自身系统时间与leaf_forever/${self}节点记录时间做比较，若小于leaf_forever/${self}时间则认为机器时间发生了大步长回拨，服务启动失败并报警。
2. 若未写过，证明是新服务节点，直接创建持久节点leaf_forever/${self}并写入自身系统时间，接下来综合对比其余Leaf节点的系统时间来判断自身系统时间是否准确，具体做法是取leaf_temporary下的所有临时节点(所有运行中的Leaf-snowflake节点)的服务IP：Port，然后通过RPC请求得到所有节点的系统时间，计算sum(time)/nodeSize。
3. 若abs( 系统时间-sum(time)/nodeSize ) < 阈值，认为当前系统时间准确，正常启动服务，同时写临时节点leaf_temporary/${self} 维持租约。
4. 否则认为本机系统时间发生大步长偏移，启动失败并报警。
5. 每隔一段时间(3s)上报自身系统时间写入leaf_forever/${self}。

## Leaf-segment数据库方案

第一种Leaf-segment方案，在使用数据库的方案上，做了如下改变： - 原方案每次获取ID都得读写一次数据库，造成数据库压力大。改为利用proxy server批量获取，每次获取一个segment(step决定大小)号段的值。**用完之后再去数据库获取新的号段，可以大大的减轻数据库的压力。** - 各个业务不同的发号需求用biz_tag字段来区分，每个biz-tag的ID获取相互隔离，互不影响。如果以后有性能需求需要对数据库扩容，不需要上述描述的复杂的扩容操作，只需要对biz_tag分库分表就行。

### 双buffer优化

对于第二个缺点，Leaf-segment做了一些优化，简单的说就是：

Leaf 取号段的时机是在号段消耗完的时候进行的，也就意味着号段临界点的ID下发时间取决于下一次从DB取回号段的时间，并且在这期间进来的请求也会因为DB号段没有取回来，导致线程阻塞。如果请求DB的网络和DB的性能稳定，这种情况对系统的影响是不大的，但是假如取DB的时候网络发生抖动，或者DB发生慢查询就会导致整个系统的响应时间变慢。

为此，我们希望DB取号段的过程能够做到无阻塞，不需要在DB取号段的时候阻塞请求线程，即当号段消费到某个点时就异步的把下一个号段加载到内存中。而不需要等到号段用尽的时候才去更新号段。这样做就可以很大程度上的降低系统的TP999指标。

采用双buffer的方式，Leaf服务内部有两个号段缓存区segment。当前号段已下发10%时，如果下一个号段未更新，则另启一个更新线程去更新下一个号段。当前号段全部下发完后，如果下个号段准备好了则切换到下个号段为当前segment接着下发，循环往复。