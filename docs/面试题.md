# Redis

**怎么样解决热Key的问题？**

1. 拆

   1. big list： list1、list2、...listN

   - big hash：可以讲数据分段存储，比如一个大的key，假设存了1百万的用户数据，可以拆分成200个key，每个key下面存放5000个用户数据

   - 如果bigkey不可避免，也要思考一下要不要每次把所有元素都取出来(例如有时候仅仅需要hmget，而不是hgetall)，删除也是一样，尽量使用优雅的方式来处理。

2. 【推荐】：选择适合的数据类型。

   例如：实体类型(要合理控制和使用数据结构，但也要注意节省内存和性能之间的平衡)

   反例：

   ```java
   set user:1:name tom set user:1:age 19 set user:1:favor football
   ```

   正例:           

   ```java
   hmset user:1 name tom age 19 favor football               
   ```

   

3. 【推荐】：控制key的生命周期，redis不是垃圾桶。

   建议使用expire设置过期时间(条件允许可以打散过期时间，防止集中过期)。开启异步删除key

   ```c++
   lazyfree-lazy-server-del //内部删除选项，比如rename oldkey newkey时，如果newkey存在需要删除newkey
   ```

**bigkey的查找**

1. **使用 Redis 自带的 --bigkeys 参数来查找。**

   从这个命令的运行结果，我们可以看出：这个命令会扫描(Scan) Redis 中的所有 key ，会对 Redis 的性能有一点影响。并且，这种方式只能找出每种数据结构 top 1 bigkey（占用内存最大的 string 数据类型，包含元素最多的复合数据类型）。

2. 通过分析 RDB 文件来找出 big key。这种方案的前提是你的 Redis 采用的是 RDB 持久化。

网上有现成的代码/工具可以直接拿来使用：

- **redis-rdb-tools**：Python 语言写的用来分析 Redis 的 RDB 快照文件用的工具
- **rdb_bigkeys**: Go 语言写的用来分析 Redis 的 RDB 快照文件用的工具，性能更好。

## hostkey

### **hotkey如何发现?**

#### **redis**自带参数

**hotkeys 参数**

`Redis` 在 `4.0.3` 版本中添加了 [hotkeys](https://github.com/redis/redis/pull/4392) 查找特性，可以直接利用 `redis-cli --hotkeys` 获取当前 `keyspace` 的热点 `key`，实现上是通过 `scan + object freq` 完成的。

- 优点：无需进行二次开发，能够直接利用现成的工具；
- 缺点：
  - 由于需要扫描整个 `keyspace`，实时性上比较差;
  - 扫描时间与 `key` 的数量正相关，如果 `key` 的数量比较多，耗时可能会非常长。

**monitor 命令**

`monitor` 命令可以实时抓取出 `Redis` 服务器接收到的命令，通过 `redis-cli monitor` 抓取数据，同时结合一些现成的分析工具，比如 [redis-faina](https://github.com/facebookarchive/redis-faina)，统计出热 Key。

- 优点：无需进行二次开发，能够直接利用现成的工具；
- 缺点：该命令在高并发的条件下，有内存增暴增的隐患，还会降低 `Redis` 的性能。

#### Redis 节点抓包分析

`Redis` 客户端使用 `TCP` 协议与服务端进行交互，通信协议采用的是 `RESP` 协议。自己写程序监听端口，按照 `RESP` 协议规则解析数据，进行分析。或者我们可以使用一些抓包工具，比如 `tcpdump` 工具，抓取一段时间内的流量进行解析。

- 优点：对 `SDK` 或者 `Proxy` 代理层没有入侵；
- 缺点：
  - 有一定的开发成本；
  - 热 `Key` 节点的网络流量和系统负载已经比较高了，抓包可能会导致情况进一步恶化。

#### 凭借业务经验，预估热 Key 出现

根据业务系统上线的一些活动和功能，我们是可以在某些场景下提前预估热 `Key` 的出现的，比如业务需要进行一场商品秒杀活动，秒杀商品信息和数量一般都会缓存到 `Redis` 中，这种场景极有可能出现热 `Key` 问题的。

- 优点：简单，凭经验发现热 `Key`，提早发现提早处理；
- 缺点：没有办法预测所有热 `Key` 出现，比如某些热点新闻事件，无法提前预测。

#### 客户端进行收集

一般我们在连接 `Redis` 服务器时都要使用专门的 SDK（比如：`Java` 的客户端工具 `Jedis`、`Redisson`），我们可以对客户端工具进行封装，在发送请求前进行收集采集，同时定时把收集到的数据上报到统一的服务进行聚合计算。

- 优点：方案简单
- 缺点：
  - 对客户端代码有一定入侵，或者需要对 `SDK` 工具进行二次开发；
  - 没法适应多语言架构，每一种语言的 `SDK` 都需要进行开发，后期开发维护成本较高。

#### 在代理层进行收集

如果所有的 `Redis` 请求都经过 `Proxy`（代理）的话，可以考虑改动 `Proxy` 代码进行收集，思路与客户端基本类似。



- 优点：对使用方完全透明，能够解决客户端 `SDK` 的语言异构和版本升级问题；
- 缺点：
  - 开发成本会比客户端高些；
  - 并不是所有的 `Redis` 集群架构中都有 `Proxy` 代理（使用这种方式必须要部署 `Proxy`）。

### 解决方案

#### 1. 使用本地缓存

在 client 端使用本地缓存，从而降低了redis集群对hot key的访问量，但是同时带来两个问题：1、如果对可能成为 hot key 的 key 都进行本地缓存，那么本地缓存是否会过大，从而影响应用程序本身所需的缓存开销。2、如何保证本地缓存和redis集群数据的有效期的一致性。 
针对这两个问题，先不展开讲，先讲第二个解决方案。

#### 2. 利用分片算法的特性，对key进行打散处理

我们知道 hot key 之所以是 hot key，是因为它只有一个key，落地到一个实例上。**所以我们可以给hot key加上前缀或者后缀，把一个hotkey 的数量变成 redis 实例个数N的倍数M，从而由访问一个 redis key 变成访问 N * M 个redis key**。通过一个大于等于 1 小于 M * N 的随机数，得到一个 tmp key，程序会优先访问tmp key，在得不到数据的情况下，再访问原来的 hot key，并将 hot key的内容写回 tmp key。值得注意的是，tmp key的过期时间是 hot key 的过期时间加上一个较小的随机正整数，保证在 hot key 过期时，所有 tmp key 不会同时过期而造成缓存雪崩。这是一种通过坡度过期的方式来避免雪崩的思路，同时也可以利用原子锁来写入数据就更加的完美，减小db的压力。

# Mysql

# 分布式ID

## 美团Leaf-snowflake

**查考文章：**https://tech.meituan.com/2019/03/07/open-source-project-leaf.html

Leaf-snowflake方案完全沿用snowflake方案的bit位设计，即是“1+41+10+12”的方式组装ID号。对于workerID的分配，当服务集群数量较小的情况下，完全可以手动配置。Leaf服务规模较大，动手配置成本太高。所以使用Zookeeper持久顺序节点的特性自动对snowflake节点配置wokerID。

### 弱依赖ZooKeeper

除了每次会去ZK拿数据以外，也会在本机文件系统上缓存一个workerID文件。当ZooKeeper出现问题，恰好机器出现问题需要重启时，能保证服务能够正常启动。这样做到了对三方组件的弱依赖。一定程度上提高了SLA。

### 解决时钟问题

因为这种方案依赖时间，如果机器的时钟发生了回拨，那么就会有可能生成重复的ID号，需要解决时钟回退的问题。**主要解决方案是在leaf_forever下面保存系统时间，leaf_temporary所有运行中的Leaf-snowflake节点。**

1. 若写过，则用自身系统时间与leaf_forever/${self}节点记录时间做比较，若小于leaf_forever/${self}时间则认为机器时间发生了大步长回拨，服务启动失败并报警。
2. 若未写过，证明是新服务节点，直接创建持久节点leaf_forever/${self}并写入自身系统时间，接下来综合对比其余Leaf节点的系统时间来判断自身系统时间是否准确，具体做法是取leaf_temporary下的所有临时节点(所有运行中的Leaf-snowflake节点)的服务IP：Port，然后通过RPC请求得到所有节点的系统时间，计算sum(time)/nodeSize。
3. 若abs( 系统时间-sum(time)/nodeSize ) < 阈值，认为当前系统时间准确，正常启动服务，同时写临时节点leaf_temporary/${self} 维持租约。
4. 否则认为本机系统时间发生大步长偏移，启动失败并报警。
5. 每隔一段时间(3s)上报自身系统时间写入leaf_forever/${self}。

## Leaf-segment数据库方案

第一种Leaf-segment方案，在使用数据库的方案上，做了如下改变： - 原方案每次获取ID都得读写一次数据库，造成数据库压力大。改为利用proxy server批量获取，每次获取一个segment(step决定大小)号段的值。**用完之后再去数据库获取新的号段，可以大大的减轻数据库的压力。** - 各个业务不同的发号需求用biz_tag字段来区分，每个biz-tag的ID获取相互隔离，互不影响。如果以后有性能需求需要对数据库扩容，不需要上述描述的复杂的扩容操作，只需要对biz_tag分库分表就行。

### 双buffer优化

对于第二个缺点，Leaf-segment做了一些优化，简单的说就是：

Leaf 取号段的时机是在号段消耗完的时候进行的，也就意味着号段临界点的ID下发时间取决于下一次从DB取回号段的时间，并且在这期间进来的请求也会因为DB号段没有取回来，导致线程阻塞。如果请求DB的网络和DB的性能稳定，这种情况对系统的影响是不大的，但是假如取DB的时候网络发生抖动，或者DB发生慢查询就会导致整个系统的响应时间变慢。

为此，我们希望DB取号段的过程能够做到无阻塞，不需要在DB取号段的时候阻塞请求线程，即当号段消费到某个点时就异步的把下一个号段加载到内存中。而不需要等到号段用尽的时候才去更新号段。这样做就可以很大程度上的降低系统的TP999指标。

采用双buffer的方式，Leaf服务内部有两个号段缓存区segment。当前号段已下发10%时，如果下一个号段未更新，则另启一个更新线程去更新下一个号段。当前号段全部下发完后，如果下个号段准备好了则切换到下个号段为当前segment接着下发，循环往复。

# 分布式事务

## X/Open 分布式事务模型

X/Open DTP（X/Open Distributed Transaction Processing Reference Model）是X/Open这个组织定义的一套分布式事务的标准。这个标准提出了使用两阶段提交（2PC，Two-Phase-Commit）来保证分布式事务的完整性。X/Open DTP中包含以下三种角色。

- AP：Application，表示应用程序。
- RM：Resource Manager，表示资源管理器，比如数据库。
- TM：Transaction Manager，表示事务管理器，**一般指事务协调者**，负责协调和管理事务，提供AP编程接口或管理RM。可以理解为Spring中提供的TransactionManager。；

需要注意的是，**TM和多个RM之间的事务控制，是基于XA协议（XA Specification）来完成的。XA协议是X/Open提出的分布式事务处理规范，也是分布式事务处理的工业标准，他定义了_xa和ax_系列的函数原形及功能描述、约束等。目前Oracle、Mysql、DB2都实现了XA接口，所以它们都可以作为RM。**

## 两阶段提交

整个事务中实际上会涉及两个阶段的提交，第一阶段是事务的准备阶段，第二阶段是事务的提交或者回滚阶段。这两个阶段都是由事务管理器发起的。两个阶段提交协议的执行流程如下。

- 准备阶段：事务管理器（TM）通知资源管理器（RM）准备分支事务，记录事务日志，并告知事务管理器的准备结果。
- 提交/回滚阶段：如果所有的资源管理器（RM）在准备阶段都明确返回成功，则事务管理器（TM）向所有的资源管理器（RM）发起事务提交指令完成数据的变更。反之，如果任何一个资源管理器（RM）明确返回失败，则事务管理器（TM）会向所有资源管理器（RM）发送事务回滚指令。

两阶段提交将一个事务的处理过程分为投票和执行两个阶段，它的优点在于充分考虑到了分布式系统的不可靠因素，并且采用非常简单的方式（两阶段提交）就把由于系统不可靠而导致事务提交失败的概率降到最小。当然，它也并不是完美的，存在以下缺点。

- 同步阻塞：所有参与者（RM）都是事务阻塞型的，对于任何一次指令都必须要有明确的响应才能继续进行下一步，否则会处于阻塞状态，占用的资源一直被锁定。
- 过于保守：任何一个节点失败都会导致数据回滚。
- 事务协调者的单点故障：如果协调者在第二阶段出现了故障，那么其他的参与者（RM）会一直处于锁定状态。
- 脑裂导致数据不一致问题，在第二阶段中，事务协调者向所有参与者（RM）发送commit请求后，发生局部网络异常导致只有一部分参与者（RM）接收到了commit请求，这部分参与者（RM）收到请求后会执行commit操作，但是未收到commit请求的节点由于事务无法提交，导致数据出现不一致问题。 

## 三阶段提交协议

三阶段提交协议是两阶段提交协议的改进版本，**为了解决二阶段协议中的同步阻塞等问题，三阶段提交协议在协调者和参与者中都引入了超时机制**，三阶段提交协议的具体描述如下。

![image](https://learn.lianglianglee.com/%E4%B8%93%E6%A0%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E6%88%9845%E8%AE%B2-%E5%AE%8C/assets/CgqCHl66P8OAOon7AALWZvqApaI286.png)

- CanCommit（询问阶段）：事务协调者向参与者发送事务执行请求，询问是否可以完成指令，参与者只需要回答是或者不是即可，不需要做真正的事务操作，**这个阶段会有超时中止机制**。
- PreCommit（准备阶段）：事务协调者会根据参与者的反馈结果决定是否继续执行，如果在询问阶段所有参与者都返回可以进行操作，则事务协调者会向所有参与者发送PreCommit请求，参与者收到请求后写redo和undo日志，执行事务操作但是不提交事务，然后返回ACK响应等待事务协调者进一步通知。如果在询问阶段任意参与者返回不能执行操作的结果或者等待超时之后，协调者没有接到参与者的响应，那么事务协调者会向所有参与者发送事务中断请求,**这个阶段也会有超时中止机制**。
- DoCommit（提交或回滚阶段）：这个阶段也会存在两种结果，仍然根据上一步骤的执行结果来决定DoCommit的执行方式。如果每个参与者在PreCommit阶段都返回成功，那么事务协调者会向所有参与者发起事务提交命令。反之，如果参与者中的任意参与者返回失败或响应超时，那么事务协调者就会发起中止命令来回滚事务。**超时提交 参与者如果没有收到协调者的通知，超时之后会执行 Commit 操作。**

三阶段提交协议和两阶段提交协议相比有一些不同点：

- 增加了一个CanCommit阶段，用于询问所有参与者是否可以执行事务操作并且响应，它的好处是，可以尽早发现无法执行操作而终止后续的行为。
- 在准备阶段之后，事务协调者和参与者都引入了超时机制，一旦超时，事务协调者和参与者会继续提交事务，并且认为处于成功状态，因为在这种情况下事务默认为成功的可能性比较大。

实际上，一旦超时，在三阶段提交协议下仍然可能出现数据不一致性的情况，当然概率是比较小的。另外，最大的好处就是基于超时机制来避免资源的永久锁定。需要注意的是，不管是两阶段提交协议还是三阶段提交协议，都是数据一致性解决方案的实现，我们可以实际应用中灵活调整。比如Zookeeper集群中的数据一致性，就用到了优化版的两阶段提交协议，优化的地方在于，它不需要所有参与者在第一阶段返回成功才能提交事务，而是利用少数服从多数的投票机制来完成数据的提交或者回滚。

# JVM调优

JVM 经过这么多年的发展和验证，整体是非常健壮的。个人认为99%的情况下，基本用不到 JVM 调优。首先如果使用合理的JVM参数设置，在大多数情况应该是不需要调优的，JVM研发团队本身设置的参数就可以应对绝大部分场景，当有小部分问题需要调优的时候，也可以通过指标配置监控警告或者console控制台频繁gc或系统响应延迟等问题发现。当指标出现波动或者异常时，能及时介入排查。



Jackson进行反序列化时会讲key进行String#intern，导致扫描时，GCRoot变大

## GC日志常用参数

```java
// 打印GC的详细信息
-XX:+PrintGCDetails
// 打印GC的时间戳
-XX:+PrintGCDateStamps
// 在GC前后打印堆信息
-XX:+PrintHeapAtGC
// 打印Survivor区中各个年龄段的对象的分布信息
-XX:+PrintTenuringDistribution
// JVM启动时输出所有参数值，方便查看参数是否被覆盖
-XX:+PrintFlagsFinal
// 打印GC时应用程序的停止时间
-XX:+PrintGCApplicationStoppedTime
// 打印在GC期间处理引用对象的时间（仅在PrintGCDetails时启用）
-XX:+PrintReferenceGC
```



# 自生成Class文件的方式

1、DebuggingClassWriter：cglib生成class文件写入的方式

2、ClassFileAssembler：method.invoke 超过inflation threadshold时候生成class文件的方式



# ThreadLocal内存泄漏的问题？

1. 局部变量引用threadlocal对象用完之后正常是回收，因为Thread.threadlocalmap的entry数组里面entry对象引用着threadlocal对象导致回收不了，已解决，key声明为weekrefernence类型。
2. 使用tomcat都是线程池的，由于key为null了，但是value还是有值的，这个entry就会一直跟随着线程存在，已解决使用remove方法，删除当前threadlocal，并且也会删除key为null的对象。

# 线上服务CPU飙升如何排查？

1. 通过**top**命令，查看占用的cpu情况，找到java占用的pid。pid代表是我们的进程ID。
2. 通过**ps - mp**命令把这个pid下的线程占用cpu情况查出来然后把这个id转换成16进制的数字。**printf "%x\n"** tid
3. 用jstack配合我们的**pid**和**tid**就能找到线程的运行状态 **jstack pid ｜grep tid ？？ problem.txt**